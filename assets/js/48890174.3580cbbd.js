"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1565],{1418:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var l=a(87462),n=(a(67294),a(3905));const i={sidebar_position:1},o="Deploy llama-2 on AWS",r={unversionedId:"tutorials/llama2-on-aws",id:"tutorials/llama2-on-aws",title:"Deploy llama-2 on AWS",description:"This tutorial demonstrates how to deploy llama-2 using Walrus on AWS with CPU, and utilize it through a user-friendly web UI.",source:"@site/docs/tutorials/llama2-on-aws.md",sourceDirName:"tutorials",slug:"/tutorials/llama2-on-aws",permalink:"/docs/tutorials/llama2-on-aws",draft:!1,editUrl:"https://github.com/seal-io/docs/edit/main/docs/tutorials/llama2-on-aws.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"docs",previous:{title:"Create a Catalog on GitHub",permalink:"/docs/tutorials/catalog-on-github"},next:{title:"Integration with CI/CD Tools",permalink:"/docs/tutorials/integrate-with-cicd"}},s={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"The Simple Way",id:"the-simple-way",level:2},{value:"Add the llama-2 Service Template",id:"add-the-llama-2-service-template",level:3},{value:"Configure Environment and AWS Credentials",id:"configure-environment-and-aws-credentials",level:3},{value:"Create the llama-2 Service",id:"create-the-llama-2-service",level:3},{value:"Accessing the llama-2 Web UI",id:"accessing-the-llama-2-web-ui",level:3},{value:"Deep Dive: Building the llama-2 Image from Scratch",id:"deep-dive-building-the-llama-2-image-from-scratch",level:2}],d={toc:c};function m(e){let{components:t,...i}=e;return(0,n.kt)("wrapper",(0,l.Z)({},d,i,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"deploy-llama-2-on-aws"},"Deploy llama-2 on AWS"),(0,n.kt)("p",null,"This tutorial demonstrates how to deploy llama-2 using Walrus on AWS with CPU, and utilize it through a user-friendly web UI."),(0,n.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,n.kt)("p",null,"To follow this tutorial, you will need:"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"An AWS account with associated ",(0,n.kt)("a",{parentName:"li",href:"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html"},"credentials"),", and sufficient permissions to create EC2 instances."),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("a",{parentName:"li",href:"/deploy/standalone"},"Walrus installed"),".")),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},"Note:\nWhile using CPU is cheaper than GPU, it still incurs costs corresponding to the EC2 instance.")),(0,n.kt)("h2",{id:"the-simple-way"},"The Simple Way"),(0,n.kt)("p",null,"With Walrus, you can have a running llama-2 instance on AWS with a user-friendly web UI in about a minute. Just follow these steps:"),(0,n.kt)("h3",{id:"add-the-llama-2-service-template"},"Add the llama-2 Service Template"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"Log in to Walrus, click on ",(0,n.kt)("inlineCode",{parentName:"li"},"Operations Center")," in the left navigation, go to the ",(0,n.kt)("inlineCode",{parentName:"li"},"Templates")," tab, and click the ",(0,n.kt)("inlineCode",{parentName:"li"},"New Template")," button."),(0,n.kt)("li",{parentName:"ol"},"Enter a template name, e.g., ",(0,n.kt)("inlineCode",{parentName:"li"},"llama-2"),"."),(0,n.kt)("li",{parentName:"ol"},"In the source field, enter ",(0,n.kt)("inlineCode",{parentName:"li"},"https://github.com/walrus-tutorials/llama2-on-aws"),"."),(0,n.kt)("li",{parentName:"ol"},"Click ",(0,n.kt)("inlineCode",{parentName:"li"},"Save"),".")),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"llama2-add-template",src:a(91433).Z,width:"4368",height:"2274"})),(0,n.kt)("h3",{id:"configure-environment-and-aws-credentials"},"Configure Environment and AWS Credentials"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"In the left navigation, click on ",(0,n.kt)("inlineCode",{parentName:"li"},"Application Management"),", go to the ",(0,n.kt)("inlineCode",{parentName:"li"},"default")," project view, and click the ",(0,n.kt)("inlineCode",{parentName:"li"},"Connectors")," tab."),(0,n.kt)("li",{parentName:"ol"},"Click the ",(0,n.kt)("inlineCode",{parentName:"li"},"New Connector")," button and select the ",(0,n.kt)("inlineCode",{parentName:"li"},"Cloud Provider")," type."),(0,n.kt)("li",{parentName:"ol"},"Enter a connector name, e.g., ",(0,n.kt)("inlineCode",{parentName:"li"},"aws"),"."),(0,n.kt)("li",{parentName:"ol"},"Choose ",(0,n.kt)("inlineCode",{parentName:"li"},"AWS")," for the ",(0,n.kt)("inlineCode",{parentName:"li"},"Type")," option."),(0,n.kt)("li",{parentName:"ol"},"Select ",(0,n.kt)("inlineCode",{parentName:"li"},"Tokyo (ap-northeast-1)")," for the ",(0,n.kt)("inlineCode",{parentName:"li"},"Region")," option."),(0,n.kt)("li",{parentName:"ol"},"Click ",(0,n.kt)("inlineCode",{parentName:"li"},"Save"),".")),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},"Note:\nThe specified region is used here because the subsequent steps involve using an AMI from that region. If you want to use a different region, you can export the AMI to your region or refer to the following sections on how to build the llama-2 image from scratch.")),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"llama2-add-connector",src:a(61753).Z,width:"4370",height:"2276"})),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"Click the ",(0,n.kt)("inlineCode",{parentName:"li"},"Environments")," tab, click the ",(0,n.kt)("inlineCode",{parentName:"li"},"New Environment")," button."),(0,n.kt)("li",{parentName:"ol"},"Enter an environment name, e.g., ",(0,n.kt)("inlineCode",{parentName:"li"},"dev"),"."),(0,n.kt)("li",{parentName:"ol"},"Click the ",(0,n.kt)("inlineCode",{parentName:"li"},"Add Connector")," button and select the ",(0,n.kt)("inlineCode",{parentName:"li"},"aws")," connector created in the previous step."),(0,n.kt)("li",{parentName:"ol"},"Click ",(0,n.kt)("inlineCode",{parentName:"li"},"Save"),".")),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"llama2-add-environment",src:a(64792).Z,width:"4366",height:"2280"})),(0,n.kt)("h3",{id:"create-the-llama-2-service"},"Create the llama-2 Service"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"In the ",(0,n.kt)("inlineCode",{parentName:"li"},"Environments")," tab, click on the name of the ",(0,n.kt)("inlineCode",{parentName:"li"},"dev")," environment to enter its view."),(0,n.kt)("li",{parentName:"ol"},"Click the ",(0,n.kt)("inlineCode",{parentName:"li"},"New Service")," button."),(0,n.kt)("li",{parentName:"ol"},"Enter a service name, e.g., ",(0,n.kt)("inlineCode",{parentName:"li"},"my-llama-2"),"."),(0,n.kt)("li",{parentName:"ol"},"Choose ",(0,n.kt)("inlineCode",{parentName:"li"},"llama-2")," in the ",(0,n.kt)("inlineCode",{parentName:"li"},"Template")," option."),(0,n.kt)("li",{parentName:"ol"},"Click ",(0,n.kt)("inlineCode",{parentName:"li"},"Save"),".")),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},"Note:\nThe default service configuration assumes your AWS account has a default VPC in the corresponding region. If you don't have a default VPC, create a new VPC, associate a subnet and a security group with it in the AWS VPC console.\nThe security group needs to open port 7860 TCP (for accessing the llama-2 web UI). You can set your VPC name and security group name in the service configuration.")),(0,n.kt)("h3",{id:"accessing-the-llama-2-web-ui"},"Accessing the llama-2 Web UI"),(0,n.kt)("p",null,"You can see the deployment and running status of the llama-2 service on its details page. Once the llama-2 service deployment is complete, you can access its web UI by clicking the access link of the service in the Walrus UI."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"llama2-service-detail",src:a(80345).Z,width:"3686",height:"2284"})),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"llama2-webui",src:a(79811).Z,width:"3538",height:"1840"})),(0,n.kt)("h2",{id:"deep-dive-building-the-llama-2-image-from-scratch"},"Deep Dive: Building the llama-2 Image from Scratch"),(0,n.kt)("p",null,"The above instructions utilized a pre-built llama-2 image. This approach saves time as you don't need to download the large language model (often with a significant file size) or build the inference service when creating a new llama-2 instance.\nThis section explains how such a llama-2 image is built."),(0,n.kt)("p",null,"You can find the complete build process ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/walrus-tutorials/llama2-on-aws/blob/build/main.tf"},"here"),"."),(0,n.kt)("p",null,"Key steps include:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-shell"},"# get text-generation-webui\ngit clone https://github.com/oobabooga/text-generation-webui && cd text-generation-webui\n# configure text-generation-webui\nln -s docker/{Dockerfile,docker-compose.yml,.dockerignore} .\ncp docker/.env.example .env\nsed -i '/^CLI_ARGS=/s/.*/CLI_ARGS=--model llama-2-7b-chat.ggmlv3.q4_K_M.bin --wbits 4 --listen --auto-devices/' .env\nsed -i '/^\\s*deploy:/,$d' docker/docker-compose.yml\n# get quantized llama-2\ncurl -L https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_K_M.bin --output ./models/llama-2-7b-chat.ggmlv3.q4_K_M.bin\n# build and run\ndocker compose up --build\n")),(0,n.kt)("p",null,"In essence, this process downloads the quantized llama-2-7b-chat model, then builds and utilizes text-generation-webui to launch the llama-2 service."))}m.isMDXComponent=!0},61753:(e,t,a)=>{a.d(t,{Z:()=>l});const l=a.p+"assets/images/llama2-add-connector-c0383dcddad20847aac31617900f58f3.png"},64792:(e,t,a)=>{a.d(t,{Z:()=>l});const l=a.p+"assets/images/llama2-add-env-5c0e81c9c8bb90a396f25e97a8dd1637.png"},91433:(e,t,a)=>{a.d(t,{Z:()=>l});const l=a.p+"assets/images/llama2-add-template-c3508d92b47c493dad7d87ca070fdcb4.png"},80345:(e,t,a)=>{a.d(t,{Z:()=>l});const l=a.p+"assets/images/llama2-service-detail-dc581da4686b4c0d0561d1a21a6fe065.png"},79811:(e,t,a)=>{a.d(t,{Z:()=>l});const l=a.p+"assets/images/llama2-web-ui-1d82a84f88f74bd6e3add858afa5e0b8.png"}}]);